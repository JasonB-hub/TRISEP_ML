{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "480d9392-f286-43c0-8be9-682b59f1311f",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/makagan/TRISEP_Tutorial/blob/main/sklearn_trees/DecisionTrees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886b2a1e-abc3-4e12-b263-db7818261e14",
   "metadata": {},
   "source": [
    "# Decision Tree Models\n",
    "\n",
    "Adapted from Scikit learn [example](https://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_twoclass.html#sphx-glr-auto-examples-ensemble-plot-adaboost-twoclass-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a58ad1-3381-4cdf-b115-b8abecb8c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d38db0-a298-47d1-b2cc-070de1180058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dataset\n",
    "X1, y1 = make_gaussian_quantiles(\n",
    "    cov=2.0, n_samples=200, n_features=2, n_classes=2, random_state=1\n",
    ")\n",
    "X2, y2 = make_gaussian_quantiles(\n",
    "    mean=(3, 3), cov=1.5, n_samples=300, n_features=2, n_classes=2, random_state=1\n",
    ")\n",
    "X = np.concatenate((X1, X2))\n",
    "y = np.concatenate((y1, -y2 + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1e14ed-a1f9-42e1-ba0b-c6d7839ed536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit an decision tree model\n",
    "bdt = AdaBoostClassifier( DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=200 )\n",
    "#bdt = DecisionTreeClassifier(max_depth=None)\n",
    "#bdt = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "bdt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c7385d-1d93-4789-888b-2dcbd79c54c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_colors = \"br\"\n",
    "plot_step = 0.02\n",
    "class_names = \"AB\"\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot the decision boundaries\n",
    "ax = plt.subplot(121)\n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    bdt,\n",
    "    X,\n",
    "    cmap=plt.cm.Paired,\n",
    "    response_method=\"predict\",\n",
    "    ax=ax,\n",
    "    xlabel=\"x\",\n",
    "    ylabel=\"y\",\n",
    ")\n",
    "x_min, x_max = disp.xx0.min(), disp.xx0.max()\n",
    "y_min, y_max = disp.xx1.min(), disp.xx1.max()\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "# Plot the training points\n",
    "for i, n, c in zip(range(2), class_names, plot_colors):\n",
    "    idx = np.where(y == i)\n",
    "    plt.scatter(\n",
    "        X[idx, 0],\n",
    "        X[idx, 1],\n",
    "        c=c,\n",
    "        cmap=plt.cm.Paired,\n",
    "        s=20,\n",
    "        edgecolor=\"k\",\n",
    "        label=\"Class %s\" % n,\n",
    "    )\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.title(\"Decision Boundary\")\n",
    "\n",
    "# Plot the two-class decision scores\n",
    "twoclass_output = bdt.decision_function(X)\n",
    "plot_range = (twoclass_output.min(), twoclass_output.max())\n",
    "plt.subplot(122)\n",
    "for i, n, c in zip(range(2), class_names, plot_colors):\n",
    "    plt.hist(\n",
    "        twoclass_output[y == i],\n",
    "        bins=10,\n",
    "        range=plot_range,\n",
    "        facecolor=c,\n",
    "        label=\"Class %s\" % n,\n",
    "        alpha=0.5,\n",
    "        edgecolor=\"k\",\n",
    "    )\n",
    "x1, x2, y1, y2 = plt.axis()\n",
    "plt.axis((x1, x2, y1, y2 * 1.2))\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylabel(\"Samples\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.title(\"Decision Scores\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.35)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
